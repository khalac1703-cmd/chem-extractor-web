import io, os, json, html, tempfile
import streamlit as st
from typing import List
from bs4 import BeautifulSoup
from chem_rules import chem_transform_v3, clean_footer
# --- Option sanitizer (ABCD) ---
import re
from typing import List

# A./B./C./D./ƒê. (ch·∫•p nh·∫≠n c√≥/kh√¥ng kho·∫£ng tr·∫Øng; d·∫•u . ho·∫∑c ))
OPT_LABEL = r'(?:[A-Dƒê])\s*[.)]'

# T√°ch nhi·ªÅu nh√£n A/B/C/D n·∫øu ch√∫ng xu·∫•t hi·ªán n·ªëi ti·∫øp nhau tr√™n c√πng 1 d√≤ng
# V√≠ d·ª•: "A. 10   B. 20   C. 30" -> t√°ch th√†nh 3 d√≤ng
MULTI_OPT_SPLIT_RE = re.compile(r'\s+(?=([A-Dƒê])\s*[.)]\s+)')

# Nh·∫≠n di·ªán 1 d√≤ng ƒë√°p √°n b·∫Øt ƒë·∫ßu b·∫±ng A./B./C./D./ƒê.
LINE_OPT_RE = re.compile(r'^\s*([A-Dƒê])\s*[.)]\s*(.*)$')

def sanitize_lines_for_options(lines: List[str]) -> List[str]:
    out: List[str] = []

    # 1) T√°ch c√°c nh√£n n·∫øu c√≥ nhi·ªÅu ƒë√°p √°n tr√™n c√πng m·ªôt d√≤ng
    expanded: List[str] = []
    for ln in lines:
        ln = ln.rstrip().rstrip("\u00A0")  # b·ªè space/NBSP cu·ªëi d√≤ng
        # N·∫øu c√≥ t·ª´ 2 nh√£n tr·ªü l√™n tr√™n 1 d√≤ng
        if re.search(OPT_LABEL + r'.*\s+' + OPT_LABEL, ln):
            parts = MULTI_OPT_SPLIT_RE.split(ln)
            buf = ""
            for p in parts:
                if re.fullmatch(r'[A-Dƒê]', p or ""):
                    if buf.strip():
                        expanded.append(buf.strip())
                    buf = p + ". "
                else:
                    buf += (p or "")
            if buf.strip():
                expanded.append(buf.strip())
        else:
            expanded.append(ln)

    # 2) √âp ƒë·ªãnh d·∫°ng chu·∫©n morat: "A. {body}" (ƒë√∫ng 1 kho·∫£ng tr·∫Øng sau "A.")
    tmp: List[str] = []
    for ln in expanded:
        m = LINE_OPT_RE.match(ln)
        if m:
            label, body = m.group(1), m.group(2).lstrip()
            ln = f"{label}. {body}"
        tmp.append(ln)

    # 3) Xo√° d√≤ng tr·ªëng gi·ªØa c√°c ƒë√°p √°n li√™n ti·∫øp
    def is_option(s: str) -> bool:
        return bool(LINE_OPT_RE.match(s))

    for i, ln in enumerate(tmp):
        if ln.strip() == "":
            prev_is_opt = i > 0 and is_option(tmp[i-1])
            next_is_opt = i+1 < len(tmp) and is_option(tmp[i+1])
            if prev_is_opt and next_is_opt:
                continue  # b·ªè d√≤ng tr·ªëng xen gi·ªØa c√°c ƒë√°p √°n
        out.append(ln)

    return out

# -------- PDF text extraction --------
def extract_text_from_pdf(file_bytes: bytes) -> str:
    from pdfminer.high_level import extract_text
    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
        tmp.write(file_bytes)
        tmp_path = tmp.name
    try:
        return extract_text(tmp_path)
    finally:
        os.unlink(tmp_path)

def to_html(lines: List[str], normalize_arrows: bool) -> str:
    parts = ['<html><head><meta charset="utf-8"><title>Chem</title></head>'
             '<body style="font-family:Times New Roman,serif; line-height:1.35; font-size:14px; white-space:pre-wrap;">']
    for ln in lines:
        ln = ln.rstrip()   # <<< quan tr·ªçng: b·ªè space ·ªü cu·ªëi d√≤ng
        parts.append(f"<div>{chem_transform_v3(ln, normalize_arrows)}</div>")
    parts.append("</body></html>")
    return "\n".join(parts)
# ---- HTML -> DOCX (gi·ªØ sub/sup + basic bold/italic n·∫øu c√≥ trong HTML) ----
def html_to_docx(chem_html: str) -> bytes:
    from docx import Document
    doc = Document()
    soup = BeautifulSoup(chem_html, "lxml")

    def add_nodes(parent, paragraph):
        for node in parent.children:
            if isinstance(node, str):
                txt = node.rstrip()          # <<< b·ªè space cu·ªëi
                if txt: paragraph.add_run(txt)
            else:
                tag = node.name.lower()
                if tag == "sub":
                    r = paragraph.add_run(node.get_text().rstrip()); r.font.subscript = True
                elif tag == "sup":
                    r = paragraph.add_run(node.get_text().rstrip()); r.font.superscript = True
                elif tag in ("b","strong"):
                    r = paragraph.add_run(node.get_text().rstrip()); r.bold = True
                elif tag in ("i","em"):
                    r = paragraph.add_run(node.get_text().rstrip()); r.italic = True
                else:
                    if node.contents:
                        add_nodes(node, paragraph)
                    else:
                        t = node.get_text().rstrip()
                        if t: paragraph.add_run(t)

    for div in soup.select("body > div, p"):
        p = doc.add_paragraph()
        add_nodes(div, p)

    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# ---------------- UI ----------------
st.set_page_config(page_title="Chem Extractor Web", page_icon="üß™", layout="wide")
st.title("üß™ Chem Extractor Web ‚Äî PDF ‚Üí HTML/DOCX")
st.caption("Gi·ªØ ch·ªâ s·ªë d∆∞·ªõi/tr√™n (chem-aware), c√¥ng t·∫Øc chu·∫©n ho√° m≈©i t√™n, b·ªè footer/s·ªë trang, xu·∫•t Word (.docx)")

colA, colB = st.columns(2)
normalize = colA.toggle("Chu·∫©n ho√° m≈©i t√™n ASCII ‚Üí Unicode", value=True)
drop_footer = colB.toggle("B·ªè footer / s·ªë trang", value=True)

uploaded = st.file_uploader("T·∫£i ƒë·ªÅ (.pdf ‚Äî ∆∞u ti√™n PDF text-based; n·∫øu .docx h√£y l∆∞u ra PDF r·ªìi t·∫£i)", type=["pdf","docx"])
if uploaded is not None:
    if uploaded.type.endswith("pdf"):
        text = extract_text_from_pdf(uploaded.getvalue())
    else:
        st.warning("B·∫£n web hi·ªán h·ªó tr·ª£ PDF t·ªët nh·∫•t. H√£y l∆∞u Word ra PDF r·ªìi t·∫£i l√™n.")
        text = ""

    if not text.strip():
        st.error("Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c text. Ki·ªÉm tra file c√≥ ph·∫£i scan/·∫£nh kh√¥ng.")
    else:
        lines = text.replace("\r\n","\n").replace("\r","\n").split("\n")
        if drop_footer:
            lines, removed = clean_footer(lines)
            st.write("Removed lines:", removed)
         # H·ª£p nh·∫•t c√°c ƒëo·∫°n vƒÉn b·ªã ng·∫Øt d√≤ng gi·ªØa ch·ª´ng (Nomex, m√¥ t·∫£ d√†i,...)
         from chem_rules import merge_broken_paragraphs
         lines = merge_broken_paragraphs(lines)
         lines = sanitize_lines_for_options(lines)
            with st.expander("D√≤ng ƒë√£ lo·∫°i b·ªè (footer/s·ªë trang)"):
                st.json(removed)

        html_out = to_html(lines, normalize_arrows=normalize)

        st.subheader("Xem tr∆∞·ªõc HTML (chem-aware)")
        st.components.v1.html(html_out, height=600, scrolling=True)

        st.download_button("‚¨áÔ∏è T·∫£i HTML", data=html_out.encode("utf-8"),
                           file_name="chem_exam.html", mime="text/html")

        docx_bytes = html_to_docx(html_out)
        st.download_button("‚¨áÔ∏è T·∫£i Word (.docx)", data=docx_bytes,
                           file_name="chem_exam.docx",
                           mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")
