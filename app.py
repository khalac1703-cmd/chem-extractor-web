import io, os, json, html, tempfile
import streamlit as st
from typing import List
from bs4 import BeautifulSoup
from chem_rules import chem_transform_v3, clean_footer
import re
OPTION_LABEL_RE = re.compile(r'^\s*([A-Dƒê])\s*[.)]\s+(.*)$')

def sanitize_lines_for_options(lines: List[str]) -> List[str]:
    fixed = []
    for ln in lines:
        ln = ln.rstrip().rstrip("\u00A0")  # c·∫Øt space & NBSP ·ªü cu·ªëi d√≤ng
        m = OPTION_LABEL_RE.match(ln)
        if m:
            label, body = m.group(1), m.group(2)
            # Y√äU C·∫¶U: b·ªè lu√¥n kho·∫£ng tr·∫Øng sau nh√£n
            ln = f"{label}.{body}"
            # N·∫øu mu·ªën GI·ªÆ 1 kho·∫£ng tr·∫Øng: ln = f"{label}. {body}"
        fixed.append(ln)
    return fixed
# -------- PDF text extraction --------
def extract_text_from_pdf(file_bytes: bytes) -> str:
    from pdfminer.high_level import extract_text
    with tempfile.NamedTemporaryFile(suffix=".pdf", delete=False) as tmp:
        tmp.write(file_bytes)
        tmp_path = tmp.name
    try:
        return extract_text(tmp_path)
    finally:
        os.unlink(tmp_path)

def to_html(lines: List[str], normalize_arrows: bool) -> str:
    parts = ['<html><head><meta charset="utf-8"><title>Chem</title></head>'
             '<body style="font-family:Times New Roman,serif; line-height:1.35; font-size:14px; white-space:pre-wrap;">']
    for ln in lines:
        ln = ln.rstrip()   # <<< quan tr·ªçng: b·ªè space ·ªü cu·ªëi d√≤ng
        parts.append(f"<div>{chem_transform_v3(ln, normalize_arrows)}</div>")
    parts.append("</body></html>")
    return "\n".join(parts)
# ---- HTML -> DOCX (gi·ªØ sub/sup + basic bold/italic n·∫øu c√≥ trong HTML) ----
def html_to_docx(chem_html: str) -> bytes:
    from docx import Document
    doc = Document()
    soup = BeautifulSoup(chem_html, "lxml")

    def add_nodes(parent, paragraph):
        for node in parent.children:
            if isinstance(node, str):
                txt = node.rstrip()          # <<< b·ªè space cu·ªëi
                if txt: paragraph.add_run(txt)
            else:
                tag = node.name.lower()
                if tag == "sub":
                    r = paragraph.add_run(node.get_text().rstrip()); r.font.subscript = True
                elif tag == "sup":
                    r = paragraph.add_run(node.get_text().rstrip()); r.font.superscript = True
                elif tag in ("b","strong"):
                    r = paragraph.add_run(node.get_text().rstrip()); r.bold = True
                elif tag in ("i","em"):
                    r = paragraph.add_run(node.get_text().rstrip()); r.italic = True
                else:
                    if node.contents:
                        add_nodes(node, paragraph)
                    else:
                        t = node.get_text().rstrip()
                        if t: paragraph.add_run(t)

    for div in soup.select("body > div, p"):
        p = doc.add_paragraph()
        add_nodes(div, p)

    bio = io.BytesIO()
    doc.save(bio)
    return bio.getvalue()

# ---------------- UI ----------------
st.set_page_config(page_title="Chem Extractor Web", page_icon="üß™", layout="wide")
st.title("üß™ Chem Extractor Web ‚Äî PDF ‚Üí HTML/DOCX")
st.caption("Gi·ªØ ch·ªâ s·ªë d∆∞·ªõi/tr√™n (chem-aware), c√¥ng t·∫Øc chu·∫©n ho√° m≈©i t√™n, b·ªè footer/s·ªë trang, xu·∫•t Word (.docx)")

colA, colB = st.columns(2)
normalize = colA.toggle("Chu·∫©n ho√° m≈©i t√™n ASCII ‚Üí Unicode", value=True)
drop_footer = colB.toggle("B·ªè footer / s·ªë trang", value=True)

uploaded = st.file_uploader("T·∫£i ƒë·ªÅ (.pdf ‚Äî ∆∞u ti√™n PDF text-based; n·∫øu .docx h√£y l∆∞u ra PDF r·ªìi t·∫£i)", type=["pdf","docx"])
if uploaded is not None:
    if uploaded.type.endswith("pdf"):
        text = extract_text_from_pdf(uploaded.getvalue())
    else:
        st.warning("B·∫£n web hi·ªán h·ªó tr·ª£ PDF t·ªët nh·∫•t. H√£y l∆∞u Word ra PDF r·ªìi t·∫£i l√™n.")
        text = ""

    if not text.strip():
        st.error("Kh√¥ng tr√≠ch xu·∫•t ƒë∆∞·ª£c text. Ki·ªÉm tra file c√≥ ph·∫£i scan/·∫£nh kh√¥ng.")
    else:
        lines = text.replace("\r\n","\n").replace("\r","\n").split("\n")
        if drop_footer:
            lines, removed = clean_footer(lines)
            lines = sanitize_lines_for_options(lines)
            with st.expander("D√≤ng ƒë√£ lo·∫°i b·ªè (footer/s·ªë trang)"):
                st.json(removed)

        html_out = to_html(lines, normalize_arrows=normalize)

        st.subheader("Xem tr∆∞·ªõc HTML (chem-aware)")
        st.components.v1.html(html_out, height=600, scrolling=True)

        st.download_button("‚¨áÔ∏è T·∫£i HTML", data=html_out.encode("utf-8"),
                           file_name="chem_exam.html", mime="text/html")

        docx_bytes = html_to_docx(html_out)
        st.download_button("‚¨áÔ∏è T·∫£i Word (.docx)", data=docx_bytes,
                           file_name="chem_exam.docx",
                           mime="application/vnd.openxmlformats-officedocument.wordprocessingml.document")
